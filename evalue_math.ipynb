{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neg_score and pos_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# run_name =  'rm_hh_rlhf_202411100543'\n",
    "from gpt import GPT, GPTRewardModel\n",
    "from configs import get_configs\n",
    "from dataset import StepDPODataset\n",
    "import torch\n",
    "from loss import KPairwiseLoss, CrossEntropyLoss, ValueLoss, PolicyLoss\n",
    "import statistics\n",
    "import datasets\n",
    "cfg = get_configs('gpt2-medium')\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Math\n",
    "sft_model = GPT.from_checkpoint(cfg, 'runs\\sft_metaMath_202412210335\\sft_metaMath_202412210335_step161558.pt')\n",
    "ppo_model = GPT.from_checkpoint(cfg, 'runs\\ppo_metaMath2212_202412221836\\ppo_metaMath2212_202412221836_actor_step500.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gpt2_input(prompt, device):\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    encode = lambda s: enc.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "    decode = lambda l: enc.decode(l)\n",
    "    indices = encode(prompt)\n",
    "    x = (torch.tensor(indices, dtype=torch.long, device=device)[None, ...])\n",
    "    return x, decode\n",
    "\n",
    "\n",
    "def generate_math_gpt2(model, prompt, device, samples=100):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    max_new_tokens = 512\n",
    "    temperature = 0.2\n",
    "    top_k = 50\n",
    "    x, decode = prepare_gpt2_input(prompt, device)\n",
    "    list_ans = dict()\n",
    "    cnt=0\n",
    "    for k in range(samples):\n",
    "        y = model.generate(x,\n",
    "                           max_new_tokens,\n",
    "                           temperature=temperature,\n",
    "                           top_k=top_k)\n",
    "        s = decode(y[0].tolist())\n",
    "        try:\n",
    "            ori_ans = s[s.index('The answer is') + len('The answer is'):].strip()\n",
    "            ans = ori_ans[:ori_ans.index('<|endoftext|>')]\n",
    "            ans = ans.strip()\n",
    "            if ans not in list_ans:\n",
    "                list_ans[ans] = 1\n",
    "            else:\n",
    "                list_ans[ans]+=1\n",
    "        except Exception as e:\n",
    "            cnt+=1\n",
    "            print('Error: ', e)\n",
    "            print(s)\n",
    "    print(f'{cnt} samples with unknown answer')\n",
    "    return list_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('gsm8k', \"main\")\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "question = 'problem'\n",
    "answer = 'answer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error1 = 0\n",
    "abs_error2 = 0\n",
    "plot_error1 = []\n",
    "plot_error2 = []\n",
    "for i in range(10):\n",
    "    prompt = train_dataset[i][question]\n",
    "    print(prompt)\n",
    "    ans_sft = generate_math_gpt2(sft_model, prompt, 'cuda', samples=10)\n",
    "    sorted_ans = dict(sorted(ans_sft.items(), key=lambda item: -item[1]))\n",
    "    #get first answer\n",
    "    ans = list(sorted_ans.keys())[0]\n",
    "    print(ans)\n",
    "    print(generate_math_gpt2(ppo_model, prompt, 'cuda', samples=10))\n",
    "    sorted_ans = dict(sorted(ans_sft.items(), key=lambda item: -item[1]))\n",
    "    #get first answer\n",
    "    ans2 = list(sorted_ans.keys())[0]\n",
    "    print(ans2)\n",
    "    true_ans = train_dataset[i][answer]\n",
    "    true_ans = true_ans[true_ans.rindex(r'####') + 4:].strip()\n",
    "    abs_error1 += abs(int(ans) - int(true_ans))\n",
    "    abs_error2 += abs(int(ans2) - int(true_ans))\n",
    "    print('True answer: ', true_ans)\n",
    "    print('Answer 1: ', ans)\n",
    "    print('Answer 2: ', ans2)\n",
    "    print('------------------------------------')\n",
    "    plot_error1.append(abs(int(ans) - int(true_ans)))\n",
    "    plot_error2.append(abs(int(ans2) - int(true_ans)))\n",
    "plt.plot(plot_error1, label='Error 1')\n",
    "plt.plot(plot_error2, label='Error 2')\n",
    "print('Average error 1: ', abs_error1/10)\n",
    "print('Average error 2: ', abs_error2/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
